{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import moviepy.editor as mpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh_min=20, thresh_max=110):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(30, 100)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    grad_mag = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    scaled_mag = np.uint8(255 * grad_mag / np.max(grad_mag))\n",
    "    binary_output = np.zeros_like(scaled_mag)\n",
    "    binary_output[(scaled_mag >= mag_thresh[0]) & (scaled_mag <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0.7, 1.3)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    grad_dir = np.arctan2(np.absolute(sobel_y), np.absolute(sobel_x))\n",
    "    binary_output = np.zeros_like(grad_dir)\n",
    "    binary_output[(grad_dir >= thresh[0]) & (grad_dir <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def lab_threshold(image, thresh_l=(200, 255), thresh_a=(-128, 128), thresh_b=(-128, 128)):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "    L, a, b = cv2.split(lab)\n",
    "    \n",
    "    l_binary = np.zeros_like(L)\n",
    "    l_binary[(L > thresh_l[0]) & (L <= thresh_l[1])] = 1\n",
    "    \n",
    "    a_binary = np.zeros_like(a)\n",
    "    a_binary[(a > thresh_a[0]) & (a <= thresh_a[1])] = 1\n",
    "    \n",
    "    b_binary = np.zeros_like(b)\n",
    "    b_binary[(b > thresh_b[0]) & (b <= thresh_b[1])] = 1\n",
    "    \n",
    "    return l_binary, a_binary, b_binary\n",
    "\n",
    "\n",
    "def combined_gradient(image):\n",
    "    ksize = 7  # Sobel kernel size\n",
    "\n",
    "    # Reduce the number of transformations\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh_min=20, thresh_max=110)\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh_min=20, thresh_max=110)\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(90, 200))\n",
    "    \n",
    "    # Combine grad_x, grad_y and mag_binary (dir_binary removed for speed)\n",
    "    combined = np.zeros_like(mag_binary)\n",
    "    combined[(gradx == 1) | (grady == 1) | (mag_binary == 1)] = 1\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Points for ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar los puntos seleccionados\n",
    "selected_points = []\n",
    "\n",
    "# Función para manejar la selección de puntos en la imagen\n",
    "def select_points(event, x, y, flags, param):\n",
    "    global selected_points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Al hacer clic izquierdo, agregamos el punto seleccionado a la lista\n",
    "        if len(selected_points) < 4:  # Solo permitir 4 puntos\n",
    "            selected_points.append((x, y))\n",
    "            print(f\"Point {len(selected_points)} selected: ({x}, {y})\")\n",
    "        if len(selected_points) == 4:\n",
    "            print(\"4 points selected. Press 'q' to continue.\")\n",
    "\n",
    "# Función para seleccionar los puntos en la imagen\n",
    "def select_points_on_image(image):\n",
    "    global selected_points\n",
    "    selected_points = []  # Limpiar puntos seleccionados antes de comenzar\n",
    "\n",
    "    # Crear una ventana para mostrar la imagen\n",
    "    cv2.imshow(\"Select 4 Points\", image)\n",
    "    cv2.setMouseCallback(\"Select 4 Points\", select_points)\n",
    "\n",
    "    # Esperar a que el usuario seleccione los 4 puntos\n",
    "    while len(selected_points) < 4:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):  # Permitir salir si presionas 'q'\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Devolver los puntos seleccionados\n",
    "    return selected_points\n",
    "\n",
    "\n",
    "# Select the ROI on the diferent images AND SELECT the ROI as a mean of the 4 points selected\n",
    "# THE ORDER OF SELECTION IS bottom left, top left, bottom right, top right\n",
    "def select_points_on_images(images):\n",
    "    sample_images_idx = np.random.choice(len(images), 6, replace=False)\n",
    "    roi_points = []\n",
    "    for idx in sample_images_idx:\n",
    "        image = images[idx]\n",
    "        selected_points = select_points_on_image(image)\n",
    "        roi_points.append(selected_points)\n",
    "        \n",
    "    # do the mean for the 4 points selected for each image\n",
    "    roi_points = np.mean(roi_points, axis=0)\n",
    "    print(roi_points)\n",
    "    return roi_points\n",
    "\n",
    "\n",
    "# Función para dibujar el ROI en la imagen\n",
    "def draw_roi(image, roi_points):\n",
    "    if len(roi_points) == 4:\n",
    "        # Los puntos se asumen como el orden: p1, p2, p4, p3 (base inferior a base superior)\n",
    "        pts = np.array(roi_points, dtype=int)\n",
    "\n",
    "        # Dibujar el ROI (polígono) en la imagen\n",
    "        image_with_roi = image.copy()\n",
    "        cv2.polylines(image_with_roi, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Mostrar la imagen con el ROI seleccionado\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cv2.cvtColor(image_with_roi, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"No se seleccionaron suficientes puntos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perspective_transform(image, roi_points):\n",
    "    # Definir los 4 puntos de destino para la transformación\n",
    "    height, width = image.shape[:2]\n",
    "    dst_points = np.array([[0, height], [0, 0], [width, 0], [width, height]], dtype=np.float32)\n",
    "    src_points = np.array(roi_points, dtype=np.float32)\n",
    "\n",
    "    # Calcular la matriz de transformación de perspectiva\n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "    # Aplicar la transformación de perspectiva\n",
    "    warped_image = cv2.warpPerspective(image, M, (width, height))\n",
    "\n",
    "    return warped_image, dst_points, src_points\n",
    "\n",
    "\n",
    "def plot_ROI_and_perspective_transform(image, roi_points):\n",
    "    if len(roi_points) == 4:\n",
    "        warped_image, dst, src = apply_perspective_transform(image, roi_points)\n",
    "\n",
    "        # Visualizar la imagen original con los puntos seleccionados\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Original Image with Selected ROI\")\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        poly = plt.Polygon(roi_points, closed=True, fill=False, color='#FF0000')\n",
    "        plt.gca().add_patch(poly)\n",
    "\n",
    "        # Visualizar la imagen transformada\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Warped Image\")\n",
    "        plt.imshow(cv2.cvtColor(warped_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"No se seleccionaron suficientes puntos.\")\n",
    "\n",
    "    binary_warped = combined_gradient(warped_image)\n",
    " \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(binary_warped, cmap='gray')\n",
    "    plt.title(\"Binary Warped Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_histogram(binary_warped):\n",
    "    \"\"\"Calcula el histograma de la mitad inferior de una imagen binaria.\"\"\"\n",
    "    return np.sum(binary_warped[binary_warped.shape[0]//2:, :], axis=0)\n",
    "\n",
    "def find_lane_base(histogram):\n",
    "    \"\"\"Encuentra las bases de las líneas izquierda y derecha usando el histograma.\"\"\"\n",
    "    midpoint = int(histogram.shape[0] // 2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint # We add the midpoint to get the offset\n",
    "    return leftx_base, rightx_base\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sliding_window(binary_image, base_left, base_right, num_windows=15, window_margin= 150, min_pixels=300):\n",
    "    \"\"\"\n",
    "    Implementa el algoritmo del sliding window para detectar los puntos de carril.\n",
    "    \n",
    "    Parameters:\n",
    "        binary_image: Imagen binaria transformada (con perspectiva corregida).\n",
    "        base_left, base_right: Coordenadas base iniciales de los carriles izquierdo y derecho.\n",
    "        num_windows: Número de ventanas a utilizar.\n",
    "        window_margin: Ancho de cada ventana en píxeles.\n",
    "        min_pixels: Umbral mínimo de píxeles para recenter una ventana.\n",
    "    \n",
    "    Returns:\n",
    "        left_curve, right_curve: Polinomios ajustados para los carriles izquierdo y derecho.\n",
    "        left_pixels, right_pixels: Índices de los píxeles pertenecientes a cada carril.\n",
    "        detected_windows: Lista de coordenadas centrales de las ventanas detectadas.\n",
    "    \"\"\"\n",
    "    # Altura de cada ventana en píxeles\n",
    "    height_window = binary_image.shape[0] // num_windows\n",
    "\n",
    "    # Obtener las posiciones de los píxeles activados\n",
    "    pixels_y, pixels_x = binary_image.nonzero()\n",
    "\n",
    "    # Posición actual de las ventanas\n",
    "    current_left = base_left\n",
    "    current_right = base_right\n",
    "\n",
    "    # Listas para guardar los píxeles del carril y los centros de las ventanas\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "    detected_windows = []\n",
    "\n",
    "    for win in range(num_windows):\n",
    "        # Límites de las ventanas\n",
    "        y_top = binary_image.shape[0] - (win + 1) * height_window\n",
    "        y_bottom = binary_image.shape[0] - win * height_window\n",
    "        x_left_low = current_left - window_margin\n",
    "        x_left_high = current_left + window_margin\n",
    "        x_right_low = current_right - window_margin\n",
    "        x_right_high = current_right + window_margin\n",
    "\n",
    "        # Agregar las coordenadas centrales de las ventanas\n",
    "        detected_windows.append(((current_left, y_bottom), (current_right, y_bottom)))\n",
    "\n",
    "        # Encontrar píxeles dentro de cada ventana\n",
    "        valid_left = ((pixels_y >= y_top) & (pixels_y < y_bottom) &\n",
    "                      (pixels_x >= x_left_low) & (pixels_x < x_left_high)).nonzero()[0]\n",
    "        valid_right = ((pixels_y >= y_top) & (pixels_y < y_bottom) &\n",
    "                       (pixels_x >= x_right_low) & (pixels_x < x_right_high)).nonzero()[0]\n",
    "\n",
    "        # Guardar los índices de los píxeles\n",
    "        left_indices.append(valid_left)\n",
    "        right_indices.append(valid_right)\n",
    "\n",
    "        # Actualizar la posición de las ventanas si se detectan suficientes píxeles\n",
    "        if len(valid_left) > min_pixels:\n",
    "            current_left = int(np.mean(pixels_x[valid_left]))\n",
    "        if len(valid_right) > min_pixels:\n",
    "            current_right = int(np.mean(pixels_x[valid_right]))\n",
    "\n",
    "    # Concatenar índices de píxeles\n",
    "    left_indices = np.concatenate(left_indices)\n",
    "    right_indices = np.concatenate(right_indices)\n",
    "\n",
    "    # Extraer las coordenadas de los píxeles de cada carril\n",
    "    x_left = pixels_x[left_indices]\n",
    "    y_left = pixels_y[left_indices]\n",
    "    x_right = pixels_x[right_indices]\n",
    "    y_right = pixels_y[right_indices]\n",
    "\n",
    "    # Ajustar polinomios a los píxeles detectados\n",
    "    left_curve = np.polyfit(y_left, x_left, 2) if len(x_left) > 0 else None\n",
    "    right_curve = np.polyfit(y_right, x_right, 2) if len(x_right) > 0 else None\n",
    "\n",
    "    return left_curve, right_curve, left_indices, right_indices, detected_windows\n",
    "\n",
    "\n",
    "\n",
    "def visualize_results(binary_image, left_fit, right_fit, window_coords):\n",
    "    \"\"\"\n",
    "    Dibuja las ventanas del sliding window y los polinomios ajustados.\n",
    "    \n",
    "    Parameters:\n",
    "        binary_image: Imagen binaria de entrada.\n",
    "        left_fit, right_fit: Coeficientes de los polinomios ajustados.\n",
    "        window_coords: Coordenadas de las ventanas del sliding window.\n",
    "    \"\"\"\n",
    "    y_vals = np.linspace(0, binary_image.shape[0] - 1, binary_image.shape[0])\n",
    "    x_left_fit = x_right_fit = None\n",
    "\n",
    "    if left_fit is not None:\n",
    "        x_left_fit = left_fit[0] * y_vals ** 2 + left_fit[1] * y_vals + left_fit[2]\n",
    "    if right_fit is not None:\n",
    "        x_right_fit = right_fit[0] * y_vals ** 2 + right_fit[1] * y_vals + right_fit[2]\n",
    "\n",
    "    plt.imshow(binary_image, cmap='gray')\n",
    "    \n",
    "    # Dibujar ventanas en funcion del size de la imagen\n",
    "    for (left, right) in window_coords:\n",
    "        left_rect = plt.Rectangle((left[0] - 60, left[1] - 25), 120, 50, edgecolor='cyan', fill=False, linewidth=2)\n",
    "        right_rect = plt.Rectangle((right[0] - 60, right[1] - 25), 120, 50, edgecolor='orange', fill=False, linewidth=2)\n",
    "        plt.gca().add_patch(left_rect)\n",
    "        plt.gca().add_patch(right_rect)\n",
    "    \n",
    "    # Dibujar polinomios ajustados\n",
    "    if x_left_fit is not None:\n",
    "        plt.plot(x_left_fit, y_vals, color='lime', label='Carril Izquierdo')\n",
    "    if x_right_fit is not None:\n",
    "        plt.plot(x_right_fit, y_vals, color='magenta', label='Carril Derecho')\n",
    "    \n",
    "    plt.title(\"Sliding Windows y Ajuste de Carriles\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_image(image, target_size = (800,600)):\n",
    "    \"\"\"\n",
    "    Redimensiona la imagen de entrada a un tamaño objetivo.\n",
    "    \n",
    "    Parameters:\n",
    "        image: Imagen de entrada.\n",
    "        target_size: Tamaño objetivo de la imagen (ancho, alto).\n",
    "    \n",
    "    Returns:\n",
    "        Imagen redimensionada.\n",
    "    \"\"\"\n",
    "    return cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curve Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_curvature(left_fit, right_fit, y_eval):\n",
    "    \"\"\"\n",
    "    Calcula el radio de curvatura de los carriles izquierdo y derecho.\n",
    "    \n",
    "    Parameters:\n",
    "        left_fit, right_fit: Polinomios ajustados para los carriles izquierdo y derecho.\n",
    "        y_eval: La posición y (en píxeles) en la que se calcula la curvatura (generalmente en el fondo de la imagen).\n",
    "        \n",
    "    Returns:\n",
    "        left_curvature, right_curvature: Radios de curvatura de los carriles izquierdo y derecho.\n",
    "    \"\"\"\n",
    "    # Coeficientes de los polinomios para el carril izquierdo y derecho\n",
    "    A_left, B_left, C_left = left_fit\n",
    "    A_right, B_right, C_right = right_fit\n",
    "    \n",
    "    # Calculamos el radio de curvatura usando la fórmula\n",
    "    left_curvature = ((1 + (2 * A_left * y_eval + B_left) ** 2) ** 1.5) / np.abs(2 * A_left)\n",
    "    right_curvature = ((1 + (2 * A_right * y_eval + B_right) ** 2) ** 1.5) / np.abs(2 * A_right)\n",
    "    \n",
    "    return left_curvature, right_curvature\n",
    "\n",
    "def detect_car_direction(left_fit, right_fit):\n",
    "    \"\"\"\n",
    "    Detecta si el coche está yendo recto, girando a la izquierda o girando a la derecha.\n",
    "    \n",
    "    Parameters:\n",
    "        left_fit, right_fit: Polinomios ajustados para los carriles izquierdo y derecho.\n",
    "    \n",
    "    Returns:\n",
    "        direction: Dirección del coche (\"Recto\", \"Izquierda\", \"Derecha\").\n",
    "    \"\"\"\n",
    "    # Comprobar si los coeficientes A de los polinomios son cercanos a cero\n",
    "    A_left, _, _ = left_fit\n",
    "    A_right, _, _ = right_fit\n",
    "    \n",
    "    if np.abs(A_left) < 0.0001 and np.abs(A_right) < 0.0001:\n",
    "        direction = \"Recto\"\n",
    "    elif A_left > 0 and A_right > 0:\n",
    "        direction = \"Derecha\"\n",
    "    elif A_left < 0 and A_right < 0:\n",
    "        direction = \"Izquierda\"\n",
    "    else:\n",
    "        direction = \"Recto\"\n",
    "    \n",
    "    return direction\n",
    "\n",
    "\n",
    "def visualize_results_with_curvature(binary_image, left_fit, right_fit, window_coords, y_eval, original_image):\n",
    "    \"\"\"\n",
    "    Dibuja las ventanas del sliding window, los polinomios ajustados y los radios de curvatura,\n",
    "    junto con la imagen original.\n",
    "    \n",
    "    Parameters:\n",
    "        binary_image: Imagen binaria de entrada.\n",
    "        left_fit, right_fit: Coeficientes de los polinomios ajustados.\n",
    "        window_coords: Coordenadas de las ventanas del sliding window.\n",
    "        y_eval: Posición y (en píxeles) en la que se calcula la curvatura.\n",
    "        original_image: Imagen original de entrada.\n",
    "    \"\"\"\n",
    "    y_vals = np.linspace(0, binary_image.shape[0] - 1, binary_image.shape[0])\n",
    "    x_left_fit = x_right_fit = None\n",
    "\n",
    "    if left_fit is not None:\n",
    "        x_left_fit = left_fit[0] * y_vals ** 2 + left_fit[1] * y_vals + left_fit[2]\n",
    "    if right_fit is not None:\n",
    "        x_right_fit = right_fit[0] * y_vals ** 2 + right_fit[1] * y_vals + right_fit[2]\n",
    "\n",
    "    # Crear figura con 2 subgráficas (una para la imagen original y otra para la imagen procesada)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    # Mostrar la imagen original en la primera subgráfica\n",
    "    ax[0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "    ax[0].set_title(\"Imagen Original\")\n",
    "    ax[0].axis('off')  # Ocultar ejes\n",
    "\n",
    "    # Mostrar la imagen binaria procesada en la segunda subgráfica\n",
    "    ax[1].imshow(binary_image, cmap='gray')\n",
    "    \n",
    "    # Dibujar ventanas\n",
    "    for (left, right) in window_coords:\n",
    "        left_rect = plt.Rectangle((left[0] - 60, left[1] - 25), 120, 50, edgecolor='cyan', fill=False, linewidth=2)\n",
    "        right_rect = plt.Rectangle((right[0] - 60, right[1] - 25), 120, 50, edgecolor='orange', fill=False, linewidth=2)\n",
    "        ax[1].add_patch(left_rect)\n",
    "        ax[1].add_patch(right_rect)\n",
    "    \n",
    "    # Dibujar polinomios ajustados\n",
    "    if x_left_fit is not None:\n",
    "        ax[1].plot(x_left_fit, y_vals, color='lime', label='Carril Izquierdo')\n",
    "    if x_right_fit is not None:\n",
    "        ax[1].plot(x_right_fit, y_vals, color='magenta', label='Carril Derecho')\n",
    "    \n",
    "    # Calcular los radios de curvatura\n",
    "    left_curvature, right_curvature = calculate_curvature(left_fit, right_fit, y_eval)\n",
    "    direction = detect_car_direction(left_fit, right_fit)\n",
    "\n",
    "    # Radio de curvatura global\n",
    "    global_curvature = (left_curvature + right_curvature) / 2\n",
    "    curvature_text = f\"Curvatura: {global_curvature:.2f} m\"\n",
    "    direction_text = f\"Dirección: {direction}\"\n",
    "\n",
    "    ax[1].set_title(\"Sliding Windows y Ajuste de Carriles\")\n",
    "    ax[1].legend()\n",
    "    ax[1].text(50, 50, curvature_text, color='orange', fontsize=12, fontweight='bold')\n",
    "    ax[1].text(50, 100, direction_text, color='orange', fontsize=12, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()  # Ajustar el espacio entre subgráficas\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI video output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_ROI_selection_on_video(video_path):\n",
    "    \"\"\"\n",
    "    Permite seleccionar puntos de interés (ROI) en un video.\n",
    "    \n",
    "    Parameters:\n",
    "        video_path (str): Ruta del video de entrada.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de puntos ROI seleccionados.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: No se pudo abrir el video en {video_path}\")\n",
    "        return None\n",
    "\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:  # Verificar si se pudo leer el fotograma\n",
    "            break\n",
    "\n",
    "        # Redimensionar el fotograma\n",
    "        frame = downsample_image(frame, (800, 600))\n",
    "        if frame is None:  # Verificar si la redimensión fue exitosa\n",
    "            print(\"Error: No se pudo redimensionar el fotograma.\")\n",
    "            break\n",
    "\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not frames:\n",
    "        print(\"Error: No se cargaron fotogramas del video.\")\n",
    "        return None\n",
    "\n",
    "    # Seleccionar puntos ROI en las imágenes\n",
    "    roi_points = select_points_on_images(frames)\n",
    "    return roi_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 1 selected: (227, 535)\n",
      "Point 2 selected: (385, 414)\n",
      "Point 3 selected: (531, 403)\n",
      "Point 4 selected: (778, 525)\n",
      "4 points selected. Press 'q' to continue.\n",
      "Point 1 selected: (167, 537)\n",
      "Point 2 selected: (379, 407)\n",
      "Point 3 selected: (537, 407)\n",
      "Point 4 selected: (771, 499)\n",
      "4 points selected. Press 'q' to continue.\n",
      "Point 1 selected: (166, 551)\n",
      "Point 2 selected: (372, 419)\n",
      "Point 3 selected: (572, 420)\n",
      "Point 4 selected: (793, 533)\n",
      "4 points selected. Press 'q' to continue.\n",
      "Point 1 selected: (220, 542)\n",
      "Point 2 selected: (371, 410)\n",
      "Point 3 selected: (530, 404)\n",
      "Point 4 selected: (790, 518)\n",
      "4 points selected. Press 'q' to continue.\n",
      "Point 1 selected: (200, 537)\n",
      "Point 2 selected: (395, 412)\n",
      "Point 3 selected: (537, 408)\n",
      "Point 4 selected: (780, 513)\n",
      "4 points selected. Press 'q' to continue.\n",
      "Point 1 selected: (185, 548)\n",
      "Point 2 selected: (373, 423)\n",
      "Point 3 selected: (541, 411)\n",
      "Point 4 selected: (768, 518)\n",
      "4 points selected. Press 'q' to continue.\n",
      "[[194.16666667 541.66666667]\n",
      " [379.16666667 414.16666667]\n",
      " [541.33333333 408.83333333]\n",
      " [780.         517.66666667]]\n"
     ]
    }
   ],
   "source": [
    "# Comprobar que la regio de interes es correcta\n",
    "# Read the image\n",
    "video = cv2.VideoCapture('data/test_video/TEST_1080.mov')\n",
    "ret, frame = video.read()\n",
    "\n",
    "# Seleccionar los puntos de la región de interés\n",
    "roi_points = execute_ROI_selection_on_video('data/test_video/TEST_1080.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video redimensionado guardado en data/test_video/TEST_1080_downsampled.mov\n",
      "Tiempo de ejecución: 29.16 segundos\n"
     ]
    }
   ],
   "source": [
    "# mostrar un video con la region de interes seleccionada\n",
    "def downsample_video(input_path, output_path): \n",
    "    video = cv2.VideoCapture(input_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: No se pudo abrir el video en {input_path}\")\n",
    "        return\n",
    "    \n",
    "    # Crear un objeto VideoWriter para guardar el video\n",
    "    frame_width = 800\n",
    "    frame_height = 600\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Redimensionar el fotograma\n",
    "        frame = downsample_image(frame, (800, 600))\n",
    "        out.write(frame)\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Video redimensionado guardado en {output_path}\")\n",
    "\n",
    "time_ini = time.time()\n",
    "input_path = 'data/test_video/TEST_1080.mov'\n",
    "output_path = 'data/test_video/TEST_1080_downsampled.mov'\n",
    "\n",
    "downsample_video(input_path, output_path)\n",
    "time_end = time.time()\n",
    "print(f\"Tiempo de ejecución: {time_end - time_ini:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video procesado guardado en data/test_video/TEST_1080_processed.mp4\n",
      "Tiempo de ejecución: 97.97 segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_ROI_downsample(input_downsampled_path, output_path, roi_points, downsampled_size=(800, 600)): \n",
    "    video = cv2.VideoCapture(input_downsampled_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: No se pudo abrir el video en {input_downsampled_path}\")\n",
    "        return\n",
    "        \n",
    "    # Create a VideoWriter object to save the video\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    if frame_width != downsampled_size[0] or frame_height != downsampled_size[1]:\n",
    "        print(\"Error: El tamaño del video redimensionado no coincide con el tamaño de entrada.\")\n",
    "        return\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Aplicar la transformación de perspectiva\n",
    "        warped_frame, _, _ = apply_perspective_transform(frame, roi_points)\n",
    "        \n",
    "        out.write(warped_frame)\n",
    "        # aply the gradient to the warped frame\n",
    "        binary_warped = combined_gradient(warped_frame)\n",
    "        \n",
    "\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Video procesado guardado en {output_path}\")\n",
    "\n",
    "time_ini = time.time()\n",
    "input_downsampled_path = 'data/test_video/TEST_1080_downsampled.mp4'\n",
    "output_path = 'data/test_video/TEST_1080_processed.mp4'\n",
    "\n",
    "process_ROI_downsample(input_downsampled_path, output_path, roi_points)\n",
    "time_end = time.time()\n",
    "print(f\"Tiempo de ejecución: {time_end - time_ini:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del video de entrada: 800x600, 58.53 FPS\n",
      "Video procesado guardado en data/test_video/TEST_1080_processed.mp4\n",
      "Tiempo de ejecución: 203.92 segundos\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "buff = 0  # Mover 'buff' fuera de la función para que se mantenga entre fotogramas\n",
    "\n",
    "def process_frame_downsampled(frame, roi_points):\n",
    "    # Aplicar la transformación de perspectiva\n",
    "    global buff\n",
    "    warped_frame, dst_points, src_points = apply_perspective_transform(frame, roi_points)\n",
    "    binary_warped = combined_gradient(warped_frame)\n",
    "    \n",
    "    histogram = calculate_histogram(binary_warped)\n",
    "    left_base, right_base = find_lane_base(histogram)\n",
    "    left_fit, right_fit, _, _, window_coords = perform_sliding_window(binary_warped, left_base, right_base)\n",
    "\n",
    "    result = frame  # Valor predeterminado\n",
    "\n",
    "    # Crear la imagen con las líneas de los carriles\n",
    "    if left_fit is not None and right_fit is not None:\n",
    "        ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "        left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "        # Crear una imagen para dibujar las líneas de los carriles\n",
    "        warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recastear puntos para cv2.fillPoly\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Dibujar los carriles\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "        Minv = cv2.getPerspectiveTransform(dst_points, src_points)\n",
    "        newwarp = cv2.warpPerspective(color_warp, Minv, (frame.shape[1], frame.shape[0]))\n",
    "        weighted_wrap = cv2.addWeighted(frame, 1, newwarp, 0.3, 0)\n",
    "\n",
    "        # Agregar curvatura y dirección\n",
    "        if buff == 30:  # Mostrar solo cada 30 fotogramas\n",
    "            y_eval = np.max(ploty)\n",
    "            left_curvature, right_curvature = calculate_curvature(left_fit, right_fit, y_eval)\n",
    "            direction = detect_car_direction(left_fit, right_fit)\n",
    "            curvature_text = f\"Curvatura: {left_curvature:.2f} m, {right_curvature:.2f} m\"\n",
    "            direction_text = f\"Dirección: {direction}\"\n",
    "            sbuff = 0  # Reiniciar el contador\n",
    "        else:\n",
    "            curvature_text = direction_text = \"\"\n",
    "\n",
    "        buff += 1\n",
    "\n",
    "        # Dibujar texto en el frame procesado\n",
    "        cv2.putText(weighted_wrap, curvature_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(weighted_wrap, direction_text, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        result = weighted_wrap\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_video_downsampled(input_path, output_path, roi_points):\n",
    "    video = cv2.VideoCapture(input_path)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error: No se pudo abrir el video en {input_path}\")\n",
    "        return\n",
    "\n",
    "    # Crear un objeto VideoWriter para guardar el video\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    print(f\"Información del video de entrada: {frame_width}x{frame_height}, {fps:.2f} FPS\")\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Procesar el fotograma\n",
    "        processed_frame = process_frame_downsampled(frame, roi_points)\n",
    "        out.write(processed_frame)\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Video procesado guardado en {output_path}\")\n",
    "\n",
    "time_ini = time.time()\n",
    "input_path = 'data/test_video/TEST_1080_downsampled.mp4'\n",
    "output_path = 'data/test_video/TEST_1080_processed.mp4'\n",
    "\n",
    "process_video_downsampled(input_path, output_path, roi_points)\n",
    "time_end = time.time()\n",
    "print(f\"Tiempo de ejecución: {time_end - time_ini:.2f} segundos\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
